---
layout: post
title:  "机器学习西瓜书笔记-1"
date:   2019-3-20 15:55
categories: MachineLearning
tags: ml overfitting roc auc 召回
---

* content
{:toc}

# 过拟合，欠拟合
学习器在训练集上的误差称为“训练误差”， 在新样本上的误差被称为“泛化误差”

我们希望在新样本上表现得很好的学习器。

## 形成原因
导致过拟合最常见的情况是由于学习能力过于强大，以至于把训练样本中所包含的不太一般的特性都学到了。

欠拟合则多数是由于学习能力低下造成的。

## 如何规避

欠拟合：一般增加训练数据或训练轮数等
- 在决策树学习中扩展分支
- 在神经网络学习中增加训练轮数

过拟合则比较难规避。过拟合是无法彻底避免的，我们只能缓解或减小其风险。

# 评估方法
## 留出法
“留出法”直接将数据集D划分为两个互斥的集合。其中一个作为训练集，另一个作为测试集。

训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响

## 交叉验证法
cross validation： 先将数据集划分为k个大小相似的互斥集合，每次用k-1个子集作为训练集，余下的那个子集作为测试集；这样就获得了k组测试/训练集，从而可以进行k次训练和测试，最终返回k个测试结果的均值。通常称为 `k折交叉验证` 。

为减少因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次。最终的评估结果是这p次k折交叉验证结果的均值。

## 调参与最终模型
机器学习常涉及两类参数：
- 算法的参数：超参数。通常由人工设定多个参数候选值后产生模型
- 模型的参数。通过学习来产生多个候选模型


# 性能度量
## 错误率与精度
错误率是分类错误的样本数占样本总数的比例

精度则是分类正确的样本数占样本总数的比例

定义
![](https://github.com/felix0913/felix0913.github.io/blob/master/_pic/precision-1.jpg?raw=true)

## 准确率 召回率 F1
对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例（true positive）， 假正例（false positive），真反例（true negative）,假反例（false negative）四种情形。TP+FP+TN+FN=样例总数。

分类结果的“混淆矩阵”如下表
![](https://github.com/felix0913/felix0913.github.io/blob/master/_pic/confusion-matrix.jpg?raw=true)

准确率： P = TP / (TP+FP)

召回率： R = TP / (TP+FN)

准确率与召回率是一对矛盾的度量。我们经常使用F1 来度量

F1 = 2 * P * R / (P + R)

![](https://github.com/felix0913/felix0913.github.io/blob/master/_pic/f-beta.jpg?raw=true)

## ROC 与 AUC
ROC全称是“受试者工作特征”曲线。
- ROC纵轴是“真正例率”（True Positive Rate，简称TPR）
- POC横轴是“假正例率”（False Positive Rate，简称FPR）

TPR = TP / (TP + FN)

FPR = FP / (TN + FP)

![](https://github.com/felix0913/felix0913.github.io/blob/master/_pic/roc-1.jpg?raw=true)

进行学习器比较时，若一个学习器的ROC曲线被另一个学习器的曲线完全包住，则可断言后者性能优于前者；若两个学习器的ROC曲线发生交叉，则需要比较ROC曲线下的面积，即 `AUC (Area Under ROC Curve)`

AUC可通过对ROC曲线下各部分的面积求和而得。

## 代价敏感错误率与代价曲线
现实任务中不同错误所造成的损失是不同的。比如：医疗诊断时，有可能将健康人诊断为病人，即FN, 也可能将病人诊断为健康人，即FP； 两者都是犯了错误，但错误的影响时不一样的。前者只是需要进一步检查，后者可能就会丧失治疗的最佳时机。

为权衡不同类型错误所造成的不同损失，可将错误赋予“非均等代价（unequal cost）”

二分类代价矩阵
![](https://github.com/felix0913/felix0913.github.io/blob/master/_pic/cost-matrix.jpg?raw=true)

上图中，cost(ij) 指的是第i类被预测为第j类样本的代价。

![](https://github.com/felix0913/felix0913.github.io/blob/master/_pic/cost-sensitive.jpg?raw=true)